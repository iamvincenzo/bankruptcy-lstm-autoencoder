{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################\n",
    "# SOME REFERENCES: https://medium.com/towards-data-science/whats-happening-in-my-lstm-layer-dd8110ecc52f #\n",
    "##########################################################################################################\n",
    "\n",
    "#################################################################################\n",
    "# SOME REFERENCES: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html #\n",
    "#################################################################################\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\"\"\" Class for a simple LSTM. \"\"\"\n",
    "class MyLSTM(nn.Module):\n",
    "    \"\"\" Initialize configurations. \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, device, bidirectional=False):\n",
    "        super(MyLSTM, self).__init__()\n",
    "        # number of features of x\n",
    "        self.input_size = input_size\n",
    "        # number of features in the hidden state h\n",
    "        self.hidden_size = hidden_size\n",
    "        # number of recurrent layers\n",
    "        self.num_layers = num_layers\n",
    "        # number of output neurons of linear layer\n",
    "        self.output_size = output_size\n",
    "        # D parameter\n",
    "        self.directions = 2 if bidirectional else 1\n",
    "        # device\n",
    "        self.device = device\n",
    "\n",
    "        # lstm-architecture:\n",
    "        self.lstm = nn.LSTM(input_size=input_size,\n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=num_layers,\n",
    "                            batch_first=True).to(device)\n",
    "\n",
    "        # linear-layer\n",
    "        self.fc1 = nn.Sequential(\n",
    "            # we take the last cell outputs with shape (batch_size, D * hidden_size)\n",
    "            nn.Linear(self.directions * self.hidden_size, self.output_size),\n",
    "            # nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    \"\"\" Method used to define the forward pass of the input through the network during the training. \"\"\"\n",
    "    def forward(self, x):\n",
    "        # input shape (batch_size, sequence_length, number_features) when batch_first=True\n",
    "        batch_size = x.size(0)\n",
    "        # (D âˆ— num_layers, batch_size, hidden_size)\n",
    "        h_0 = torch.zeros((self.directions * self.num_layers,\n",
    "                           batch_size, self.hidden_size)).to(self.device)\n",
    "        c_0 = torch.zeros((self.directions * self.num_layers,\n",
    "                           batch_size, self.hidden_size)).to(self.device)\n",
    "\n",
    "        # output-shape (batch_size, sequence_lenght, D * hidden_size)\n",
    "        # h_n-shape (D * num_layers, batch_size, hidden_size)\n",
    "        # c_n-shape (D * num_layers, batch_size, hidden_size)\n",
    "        output, (h_n, c_n) = self.lstm(x, (h_0, c_0))\n",
    "\n",
    "        print(\"\\n\", output.shape, h_n.shape, c_n.shape)\n",
    "        print(\"\\n\", output, \"\\n\\n\", h_n, \"\\n\\n\", c_n)\n",
    "\n",
    "        # takes the last cell outputs of all batches\n",
    "        print(\"\\nlast cell outputs shape: \\n\", output[:, -1, :].shape)\n",
    "        print(\"\\nlast cell outputs: \\n\", output[:, -1, :])\n",
    "\n",
    "        lin_out = self.fc1(output[:, -1, :])\n",
    "\n",
    "        print(f\"\\nlin-out-shape: {lin_out}\")\n",
    "\n",
    "\n",
    "\"\"\" Runs the simulation. \"\"\"\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"device: {device}\")\n",
    "\n",
    "    x = torch.randn((2, 6, 6))\n",
    "    print(f\"\\nx-shape: {x.shape}\")\n",
    "\n",
    "    num_features = int(x.shape[2])\n",
    "\n",
    "    model = MyLSTM(input_size=num_features,\n",
    "                   hidden_size=6,\n",
    "                   num_layers=1,\n",
    "                   output_size=1,\n",
    "                   device=device)\n",
    "\n",
    "    out = model(x)\n",
    "\n",
    "##################\n",
    "# output example #\n",
    "##################\n",
    "\n",
    "# device: cpu\n",
    "\n",
    "# x-shape: torch.Size([2, 6, 6])\n",
    "\n",
    "# torch.Size([2, 6, 6]) torch.Size([1, 2, 6]) torch.Size([1, 2, 6])\n",
    "\n",
    "# tensor([[[ 0.0670,  0.0398,  0.2406, -0.2882,  0.0184, -0.1168],\n",
    "#          [-0.0813,  0.2598,  0.3303, -0.1901,  0.1681, -0.1573],\n",
    "#          [-0.0013,  0.0993,  0.3154, -0.2576,  0.2350, -0.2473],\n",
    "#          [ 0.1037,  0.0869,  0.3699, -0.1835,  0.0433, -0.3695],\n",
    "#          [ 0.1005,  0.2060,  0.3575, -0.1126,  0.0005, -0.3399],\n",
    "#          [ 0.0111,  0.1685,  0.4348, -0.2917,  0.1025, -0.2308]],\n",
    "\n",
    "#         [[ 0.2161, -0.0216,  0.1619, -0.0560, -0.1214, -0.2652],\n",
    "#          [ 0.1342,  0.1155,  0.3858, -0.1652, -0.1072, -0.2497],\n",
    "#          [-0.0412,  0.2684,  0.1980, -0.1152,  0.2417, -0.0435],\n",
    "#          [-0.4885,  0.4563, -0.0637, -0.1715,  0.2013,  0.0407],\n",
    "#          [-0.1746,  0.2125,  0.0317, -0.2900,  0.3504, -0.0428],\n",
    "#          [-0.3115,  0.3664, -0.0838, -0.2712,  0.2742, -0.0829]]],\n",
    "#        grad_fn=<TransposeBackward0>)\n",
    "\n",
    "# tensor([[[ 0.0111,  0.1685,  0.4348, -0.2917,  0.1025, -0.2308],\n",
    "#          [-0.3115,  0.3664, -0.0838, -0.2712,  0.2742, -0.0829]]],\n",
    "#        grad_fn=<StackBackward0>)\n",
    "\n",
    "# tensor([[[ 0.0251,  0.3550,  0.9562, -0.6240,  0.2229, -0.6161],\n",
    "#          [-0.4754,  0.7592, -0.2685, -0.7482,  0.9308, -0.2028]]],\n",
    "#        grad_fn=<StackBackward0>)\n",
    "\n",
    "# last cell outputs shape: torch.Size([2, 6])\n",
    "\n",
    "# last cell outputs:\n",
    "# tensor([[ 0.0111,  0.1685,  0.4348, -0.2917,  0.1025, -0.2308],\n",
    "#         [-0.3115,  0.3664, -0.0838, -0.2712,  0.2742, -0.0829]],\n",
    "#        grad_fn=<SliceBackward0>)\n",
    "\n",
    "# lin-out-shape:\n",
    "# tensor([[0.2285],\n",
    "#         [0.3122]], grad_fn=<ReluBackward0>)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "device: \n",
      "cpu\n",
      "\n",
      "input-shape: \n",
      "torch.Size([2, 5, 18])\n",
      "\n",
      "input: \n",
      "tensor([[[0.7559, 0.6392, 0.0092, 0.6452, 0.1449, 0.6909, 0.0577, 0.2998,\n",
      "          0.7970, 0.2855, 0.5392, 0.8484, 0.4107, 0.9068, 0.5477, 0.4698,\n",
      "          0.3176, 0.5685],\n",
      "         [0.8637, 0.8399, 0.7292, 0.2000, 0.8625, 0.0156, 0.0622, 0.5205,\n",
      "          0.6573, 0.9495, 0.6972, 0.2059, 0.5491, 0.2809, 0.8860, 0.6234,\n",
      "          0.1517, 0.2491],\n",
      "         [0.8693, 0.6708, 0.3647, 0.0499, 0.7697, 0.6454, 0.2044, 0.4120,\n",
      "          0.4847, 0.1272, 0.9818, 0.1897, 0.9270, 0.9540, 0.9138, 0.3410,\n",
      "          0.0813, 0.4835],\n",
      "         [0.5663, 0.2518, 0.0441, 0.8284, 0.2990, 0.0440, 0.7476, 0.7062,\n",
      "          0.7127, 0.4158, 0.3692, 0.9686, 0.9411, 0.8914, 0.8552, 0.9373,\n",
      "          0.8465, 0.4164],\n",
      "         [0.5319, 0.7169, 0.0394, 0.3653, 0.2439, 0.6420, 0.2193, 0.9187,\n",
      "          0.9993, 0.5404, 0.3560, 0.0227, 0.3102, 0.8633, 0.2731, 0.7243,\n",
      "          0.8787, 0.3147]],\n",
      "\n",
      "        [[0.7206, 0.8235, 0.7044, 0.4646, 0.4504, 0.4005, 0.0671, 0.5175,\n",
      "          0.5169, 0.8400, 0.6139, 0.4318, 0.9143, 0.3985, 0.2585, 0.8911,\n",
      "          0.6812, 0.0326],\n",
      "         [0.1873, 0.3557, 0.5110, 0.3804, 0.1015, 0.1986, 0.4350, 0.7379,\n",
      "          0.4630, 0.4496, 0.8290, 0.4678, 0.0024, 0.6944, 0.4367, 0.3637,\n",
      "          0.7495, 0.3880],\n",
      "         [0.6585, 0.7805, 0.2989, 0.9533, 0.0180, 0.8972, 0.2152, 0.2421,\n",
      "          0.1609, 0.2202, 0.5354, 0.6456, 0.7679, 0.1237, 0.1805, 0.1723,\n",
      "          0.6705, 0.3595],\n",
      "         [0.1048, 0.9736, 0.0588, 0.6791, 0.6128, 0.4416, 0.3680, 0.4867,\n",
      "          0.1287, 0.6058, 0.5343, 0.8262, 0.3173, 0.1549, 0.5711, 0.4160,\n",
      "          0.3636, 0.8290],\n",
      "         [0.3808, 0.2098, 0.3981, 0.4575, 0.9149, 0.9927, 0.7026, 0.8049,\n",
      "          0.2435, 0.7546, 0.0484, 0.6510, 0.1847, 0.3008, 0.4975, 0.6335,\n",
      "          0.9748, 0.1417]]])\n",
      "\n",
      "enc1-output-shape: \n",
      "torch.Size([2, 5, 9])\n",
      "\n",
      "enc1-output: \n",
      "tensor([[[ 0.1571, -0.0421, -0.1337,  0.2210,  0.0084,  0.0922,  0.2000,\n",
      "          -0.1336,  0.0459],\n",
      "         [ 0.1833, -0.0768, -0.2589,  0.2897, -0.0633,  0.2046,  0.1771,\n",
      "          -0.2044,  0.0984],\n",
      "         [ 0.2033, -0.1046, -0.2654,  0.4027,  0.0106,  0.1955,  0.1374,\n",
      "          -0.2748,  0.1045],\n",
      "         [ 0.2026, -0.0744, -0.3233,  0.3803, -0.0550,  0.2571,  0.2244,\n",
      "          -0.2065,  0.0918],\n",
      "         [ 0.2538, -0.0917, -0.4455,  0.4303, -0.1157,  0.2167,  0.2480,\n",
      "          -0.2516,  0.1278]],\n",
      "\n",
      "        [[ 0.1125, -0.0935, -0.1849,  0.2091, -0.0646,  0.1618,  0.1637,\n",
      "          -0.0826,  0.0205],\n",
      "         [ 0.2142, -0.0079, -0.2368,  0.2164, -0.1169,  0.2221,  0.2266,\n",
      "          -0.1458,  0.0980],\n",
      "         [ 0.2841, -0.0449, -0.2680,  0.1419, -0.1001,  0.2608,  0.1562,\n",
      "          -0.1812,  0.0777],\n",
      "         [ 0.3619, -0.0422, -0.2809,  0.0677, -0.1252,  0.2673,  0.1770,\n",
      "          -0.2425,  0.1583],\n",
      "         [ 0.2480, -0.0598, -0.3072,  0.1077, -0.1504,  0.2591,  0.2070,\n",
      "          -0.1969,  0.1072]]], grad_fn=<TransposeBackward0>)\n",
      "\n",
      "enc2-output-shape: \n",
      "torch.Size([2, 5, 3])\n",
      "\n",
      "enc2-output: \n",
      "tensor([[[-0.0831,  0.1295, -0.0727],\n",
      "         [-0.1191,  0.1985, -0.1086],\n",
      "         [-0.1307,  0.2375, -0.1156],\n",
      "         [-0.1429,  0.2610, -0.1337],\n",
      "         [-0.1486,  0.2804, -0.1428]],\n",
      "\n",
      "        [[-0.0920,  0.1229, -0.0810],\n",
      "         [-0.1221,  0.1956, -0.1148],\n",
      "         [-0.1464,  0.2311, -0.1258],\n",
      "         [-0.1525,  0.2597, -0.1290],\n",
      "         [-0.1573,  0.2640, -0.1366]]], grad_fn=<TransposeBackward0>)\n",
      "\n",
      "hidden_n-shape: \n",
      "torch.Size([1, 2, 3])\n",
      "\n",
      "hidden_n: \n",
      "tensor([[[-0.1486,  0.2804, -0.1428],\n",
      "         [-0.1573,  0.2640, -0.1366]]], grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "##########################################################################################################\n",
    "# SOME REFERENCES: https://medium.com/towards-data-science/whats-happening-in-my-lstm-layer-dd8110ecc52f #\n",
    "##########################################################################################################\n",
    "\n",
    "#################################################################################\n",
    "# SOME REFERENCES: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html #\n",
    "#################################################################################\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\"\"\" Class form LSTM in Autoencoder configuration. \"\"\"\n",
    "class MyAutoEncLSTM(nn.Module):\n",
    "    \"\"\" Initialize configurations. \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, embedding_dim, num_layers, device, bidirectional=False):\n",
    "        super(MyAutoEncLSTM, self).__init__()\n",
    "        # the number of expected features in the input x\n",
    "        self.input_size = input_size\n",
    "        # the number of features in the hidden state h\n",
    "        self.hidden_size = hidden_size\n",
    "        # the hidden-size of the last encoder layer\n",
    "        self.embedding_dim = embedding_dim\n",
    "        # number of recurrent layers\n",
    "        self.num_layers = num_layers\n",
    "        # if true becomes a bidirectional LSTM\n",
    "        D = 2 if bidirectional else 1\n",
    "        self.directions = D\n",
    "        # device where to put tensors\n",
    "        self.device = device\n",
    "\n",
    "        # lstm-architecture\n",
    "        self.lstm_encoder1 = nn.LSTM(input_size=input_size,\n",
    "                                     hidden_size=hidden_size,\n",
    "                                     num_layers=num_layers,\n",
    "                                     batch_first=True)\n",
    "        # lstm-architecture\n",
    "        self.lstm_encoder2 = nn.LSTM(input_size=D*hidden_size,\n",
    "                                     hidden_size=embedding_dim,\n",
    "                                     num_layers=num_layers,\n",
    "                                     batch_first=True)\n",
    "        # # lstm-architecture\n",
    "        # self.lstm_decoder1 = nn.LSTM(input_size=input_size,\n",
    "        #                              hidden_size=hidden_size,\n",
    "        #                              num_layers=num_layers,\n",
    "        #                              batch_first=True)\n",
    "        # # lstm-architecture\n",
    "        # self.lstm_decoder2 = nn.LSTM(input_size=input_size,\n",
    "        #                              hidden_size=hidden_size,\n",
    "        #                              num_layers=num_layers,\n",
    "        #                              batch_first=True)\n",
    "\n",
    "    \"\"\" Method used to define the forward pass of the input through the network during the training. \"\"\"\n",
    "    def forward(self, x):\n",
    "        # input shape (batch_size, sequence_length, number_features) when batch_first=True\n",
    "\n",
    "        # output-shape (batch_size, sequence_lenght, D * hidden_size)\n",
    "        # h_n-shape (D * num_layers, batch_size, hidden_size)\n",
    "        # c_n-shape (D * num_layers, batch_size, hidden_size)\n",
    "        enc1_output, (_, _) = self.lstm_encoder1(x)\n",
    "\n",
    "        print(f\"\\nenc1-output-shape: \\n{enc1_output.shape}\")\n",
    "        print(f\"\\nenc1-output: \\n{enc1_output}\")\n",
    "\n",
    "        enc2_output, (hidden_n, _) = self.lstm_encoder2(enc1_output)\n",
    "\n",
    "        print(f\"\\nenc2-output-shape: \\n{enc2_output.shape}\")\n",
    "        print(f\"\\nenc2-output: \\n{enc2_output}\")\n",
    "        print(f\"\\nhidden_n-shape: \\n{hidden_n.shape}\")\n",
    "        print(f\"\\nhidden_n: \\n{hidden_n}\")\n",
    "\n",
    "        # cosa prendo: ?\n",
    "        # prendo enc2_output oppure hidden_n ? --> l'architettura di rete cambia\n",
    "        # volgio un output di encoder_2 di tipo flatten per la classificazione successiva ?\n",
    "        \n",
    "        # va bene ?\n",
    "        # input [bs, 5, 18]\n",
    "        # enc1-out [bs, 5, 9]\n",
    "        # enc2-out [bs, 5, 3]\n",
    "        # dec1-out [bs, 5, 9]\n",
    "        # dec2-out [bs, 5, 18] ???\n",
    "\n",
    "        # poi classif: ?\n",
    "        # con criterion = binary-crossentropy\n",
    "        # input [bs, 5, 18]\n",
    "        # enc1-out [bs, 5, 9]\n",
    "        # flatten [bs, 5 * 9] = [bs, 45]\n",
    "        # fc1-out [45, 10]\n",
    "        # fc2-out [10, 1]\n",
    "        # sigmoide\n",
    "\n",
    "\n",
    "\"\"\" Runs the simulation. \"\"\"\n",
    "if __name__ == \"__main__\":\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"\\ndevice: \\n{device}\")\n",
    "\n",
    "    batch_size = 2\n",
    "    seq_len = 5\n",
    "    num_features = 18\n",
    "    hidden_size = 9\n",
    "    embedding_dim = 3\n",
    "    num_layers = 1    \n",
    "    x = torch.rand((batch_size, seq_len, num_features))\n",
    "\n",
    "    print(f\"\\ninput-shape: \\n{x.shape}\")\n",
    "    print(f\"\\ninput: \\n{x}\")\n",
    "\n",
    "    # model definition\n",
    "    model = MyAutoEncLSTM(input_size=num_features,\n",
    "                          hidden_size=hidden_size,\n",
    "                          embedding_dim=embedding_dim,\n",
    "                          num_layers=num_layers,\n",
    "                          device=device)\n",
    "\n",
    "    # model output\n",
    "    output = model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
