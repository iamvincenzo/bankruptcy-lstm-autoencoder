{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################\n",
    "# SOME REFERENCES: https://medium.com/towards-data-science/whats-happening-in-my-lstm-layer-dd8110ecc52f #\n",
    "##########################################################################################################\n",
    "\n",
    "#################################################################################\n",
    "# SOME REFERENCES: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html #\n",
    "#################################################################################\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\"\"\" Class for a simple LSTM. \"\"\"\n",
    "class MyLSTM(nn.Module):\n",
    "    \"\"\" Initialize configurations. \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, device, bidirectional=False):\n",
    "        super(MyLSTM, self).__init__()\n",
    "        # number of features of x\n",
    "        self.input_size = input_size\n",
    "        # number of features in the hidden state h\n",
    "        self.hidden_size = hidden_size\n",
    "        # number of recurrent layers\n",
    "        self.num_layers = num_layers\n",
    "        # number of output neurons of linear layer\n",
    "        self.output_size = output_size\n",
    "        # D parameter\n",
    "        self.directions = 2 if bidirectional else 1\n",
    "        # device\n",
    "        self.device = device\n",
    "\n",
    "        # lstm-architecture:\n",
    "        self.lstm = nn.LSTM(input_size=input_size,\n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=num_layers,\n",
    "                            batch_first=True).to(device)\n",
    "\n",
    "        # linear-layer\n",
    "        self.fc1 = nn.Sequential(\n",
    "            # we take the last cell outputs with shape (batch_size, D * hidden_size)\n",
    "            nn.Linear(self.directions * self.hidden_size, self.output_size),\n",
    "            # nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    \"\"\" Method used to define the forward pass of the input through the network during the training. \"\"\"\n",
    "    def forward(self, x):\n",
    "        # input shape (batch_size, sequence_length, number_features) when batch_first=True\n",
    "        batch_size = x.size(0)\n",
    "        # (D âˆ— num_layers, batch_size, hidden_size)\n",
    "        h_0 = torch.zeros((self.directions * self.num_layers,\n",
    "                           batch_size, self.hidden_size)).to(self.device)\n",
    "        c_0 = torch.zeros((self.directions * self.num_layers,\n",
    "                           batch_size, self.hidden_size)).to(self.device)\n",
    "\n",
    "        # output-shape (batch_size, sequence_lenght, D * hidden_size)\n",
    "        # h_n-shape (D * num_layers, batch_size, hidden_size)\n",
    "        # c_n-shape (D * num_layers, batch_size, hidden_size)\n",
    "        output, (h_n, c_n) = self.lstm(x, (h_0, c_0))\n",
    "\n",
    "        print(\"\\n\", output.shape, h_n.shape, c_n.shape)\n",
    "        print(\"\\n\", output, \"\\n\\n\", h_n, \"\\n\\n\", c_n)\n",
    "\n",
    "        # takes the last cell outputs of all batches\n",
    "        print(\"\\nlast cell outputs shape: \\n\", output[:, -1, :].shape)\n",
    "        print(\"\\nlast cell outputs: \\n\", output[:, -1, :])\n",
    "\n",
    "        lin_out = self.fc1(output[:, -1, :])\n",
    "\n",
    "        print(f\"\\nlin-out-shape: {lin_out}\")\n",
    "\n",
    "\n",
    "\"\"\" Runs the simulation. \"\"\"\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"device: {device}\")\n",
    "\n",
    "    x = torch.randn((2, 6, 6))\n",
    "    print(f\"\\nx-shape: {x.shape}\")\n",
    "\n",
    "    num_features = int(x.shape[2])\n",
    "\n",
    "    model = MyLSTM(input_size=num_features,\n",
    "                   hidden_size=6,\n",
    "                   num_layers=1,\n",
    "                   output_size=1,\n",
    "                   device=device)\n",
    "\n",
    "    out = model(x)\n",
    "\n",
    "##################\n",
    "# output example #\n",
    "##################\n",
    "\n",
    "# device: cpu\n",
    "\n",
    "# x-shape: torch.Size([2, 6, 6])\n",
    "\n",
    "# torch.Size([2, 6, 6]) torch.Size([1, 2, 6]) torch.Size([1, 2, 6])\n",
    "\n",
    "# tensor([[[ 0.0670,  0.0398,  0.2406, -0.2882,  0.0184, -0.1168],\n",
    "#          [-0.0813,  0.2598,  0.3303, -0.1901,  0.1681, -0.1573],\n",
    "#          [-0.0013,  0.0993,  0.3154, -0.2576,  0.2350, -0.2473],\n",
    "#          [ 0.1037,  0.0869,  0.3699, -0.1835,  0.0433, -0.3695],\n",
    "#          [ 0.1005,  0.2060,  0.3575, -0.1126,  0.0005, -0.3399],\n",
    "#          [ 0.0111,  0.1685,  0.4348, -0.2917,  0.1025, -0.2308]],\n",
    "\n",
    "#         [[ 0.2161, -0.0216,  0.1619, -0.0560, -0.1214, -0.2652],\n",
    "#          [ 0.1342,  0.1155,  0.3858, -0.1652, -0.1072, -0.2497],\n",
    "#          [-0.0412,  0.2684,  0.1980, -0.1152,  0.2417, -0.0435],\n",
    "#          [-0.4885,  0.4563, -0.0637, -0.1715,  0.2013,  0.0407],\n",
    "#          [-0.1746,  0.2125,  0.0317, -0.2900,  0.3504, -0.0428],\n",
    "#          [-0.3115,  0.3664, -0.0838, -0.2712,  0.2742, -0.0829]]],\n",
    "#        grad_fn=<TransposeBackward0>)\n",
    "\n",
    "# tensor([[[ 0.0111,  0.1685,  0.4348, -0.2917,  0.1025, -0.2308],\n",
    "#          [-0.3115,  0.3664, -0.0838, -0.2712,  0.2742, -0.0829]]],\n",
    "#        grad_fn=<StackBackward0>)\n",
    "\n",
    "# tensor([[[ 0.0251,  0.3550,  0.9562, -0.6240,  0.2229, -0.6161],\n",
    "#          [-0.4754,  0.7592, -0.2685, -0.7482,  0.9308, -0.2028]]],\n",
    "#        grad_fn=<StackBackward0>)\n",
    "\n",
    "# last cell outputs shape: torch.Size([2, 6])\n",
    "\n",
    "# last cell outputs:\n",
    "# tensor([[ 0.0111,  0.1685,  0.4348, -0.2917,  0.1025, -0.2308],\n",
    "#         [-0.3115,  0.3664, -0.0838, -0.2712,  0.2742, -0.0829]],\n",
    "#        grad_fn=<SliceBackward0>)\n",
    "\n",
    "# lin-out-shape:\n",
    "# tensor([[0.2285],\n",
    "#         [0.3122]], grad_fn=<ReluBackward0>)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "device: \n",
      "cpu\n",
      "\n",
      "input-shape: \n",
      "torch.Size([2, 2, 3])\n",
      "\n",
      "input: \n",
      "tensor([[[0.1134, 0.5940, 0.2335],\n",
      "         [0.6617, 0.2146, 0.2131]],\n",
      "\n",
      "        [[0.3208, 0.7989, 0.0239],\n",
      "         [0.9745, 0.4620, 0.1497]]])\n",
      "\n",
      "enc1-output-shape: \n",
      "torch.Size([2, 2, 2])\n",
      "\n",
      "enc1-output: \n",
      "tensor([[[-0.0830, -0.1466],\n",
      "         [-0.1376, -0.1690]],\n",
      "\n",
      "        [[-0.0529, -0.1436],\n",
      "         [-0.0880, -0.1840]]], grad_fn=<TransposeBackward0>)\n",
      "\n",
      "enc2-output-shape: \n",
      "torch.Size([2, 2, 1])\n",
      "\n",
      "enc2-output: \n",
      "tensor([[[0.0273],\n",
      "         [0.0558]],\n",
      "\n",
      "        [[0.0245],\n",
      "         [0.0473]]], grad_fn=<TransposeBackward0>)\n",
      "\n",
      "hidden_n-shape: \n",
      "torch.Size([1, 2, 1])\n",
      "\n",
      "hidden_n: \n",
      "tensor([[[0.0558],\n",
      "         [0.0473]]], grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "##########################################################################################################\n",
    "# SOME REFERENCES: https://medium.com/towards-data-science/whats-happening-in-my-lstm-layer-dd8110ecc52f #\n",
    "##########################################################################################################\n",
    "\n",
    "#################################################################################\n",
    "# SOME REFERENCES: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html #\n",
    "#################################################################################\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\"\"\" Class form LSTM in Autoencoder configuration. \"\"\"\n",
    "class MyAutoEncLSTM(nn.Module):\n",
    "    \"\"\" Initialize configurations. \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, embedding_dim, num_layers, device, bidirectional=False):\n",
    "        super(MyAutoEncLSTM, self).__init__()\n",
    "        # the number of expected features in the input x\n",
    "        self.input_size = input_size\n",
    "        # the number of features in the hidden state h\n",
    "        self.hidden_size = hidden_size\n",
    "        # the hidden-size of the last encoder layer\n",
    "        self.embedding_dim = embedding_dim\n",
    "        # number of recurrent layers\n",
    "        self.num_layers = num_layers\n",
    "        # if true becomes a bidirectional LSTM\n",
    "        D = 2 if bidirectional else 1\n",
    "        self.directions = D\n",
    "        # device where to put tensors\n",
    "        self.device = device\n",
    "\n",
    "        # lstm-architecture\n",
    "        self.lstm_encoder1 = nn.LSTM(input_size=input_size,\n",
    "                                     hidden_size=hidden_size,\n",
    "                                     num_layers=num_layers,\n",
    "                                     batch_first=True)\n",
    "        # lstm-architecture\n",
    "        self.lstm_encoder2 = nn.LSTM(input_size=D*hidden_size,\n",
    "                                     hidden_size=embedding_dim,\n",
    "                                     num_layers=num_layers,\n",
    "                                     batch_first=True)\n",
    "        # # lstm-architecture\n",
    "        # self.lstm_decoder1 = nn.LSTM(input_size=input_size,\n",
    "        #                              hidden_size=hidden_size,\n",
    "        #                              num_layers=num_layers,\n",
    "        #                              batch_first=True)\n",
    "        # # lstm-architecture\n",
    "        # self.lstm_decoder2 = nn.LSTM(input_size=input_size,\n",
    "        #                              hidden_size=hidden_size,\n",
    "        #                              num_layers=num_layers,\n",
    "        #                              batch_first=True)\n",
    "\n",
    "    \"\"\" Method used to define the forward pass of the input through the network during the training. \"\"\"\n",
    "    def forward(self, x):\n",
    "        # input shape (batch_size, sequence_length, number_features) when batch_first=True\n",
    "\n",
    "        # output-shape (batch_size, sequence_lenght, D * hidden_size)\n",
    "        # h_n-shape (D * num_layers, batch_size, hidden_size)\n",
    "        # c_n-shape (D * num_layers, batch_size, hidden_size)\n",
    "        enc1_output, (_, _) = self.lstm_encoder1(x)\n",
    "\n",
    "        print(f\"\\nenc1-output-shape: \\n{enc1_output.shape}\")\n",
    "        print(f\"\\nenc1-output: \\n{enc1_output}\")\n",
    "\n",
    "        enc2_output, (hidden_n, _) = self.lstm_encoder2(enc1_output)\n",
    "\n",
    "        print(f\"\\nenc2-output-shape: \\n{enc2_output.shape}\")\n",
    "        print(f\"\\nenc2-output: \\n{enc2_output}\")\n",
    "        print(f\"\\nhidden_n-shape: \\n{hidden_n.shape}\")\n",
    "        print(f\"\\nhidden_n: \\n{hidden_n}\")\n",
    "\n",
    "        # prendo enc2_output oppure hidden_n ? --> l'architettura di rete cambia\n",
    "\n",
    "\n",
    "\"\"\" Runs the simulation. \"\"\"\n",
    "if __name__ == \"__main__\":\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"\\ndevice: \\n{device}\")\n",
    "\n",
    "    batch_size = 2\n",
    "    seq_len = 2  # 5\n",
    "    num_features = 3  # 18\n",
    "    hidden_size = 2\n",
    "    embedding_dim = 1\n",
    "    num_layers = 1\n",
    "    x = torch.rand((batch_size, seq_len, num_features))\n",
    "\n",
    "    print(f\"\\ninput-shape: \\n{x.shape}\")\n",
    "    print(f\"\\ninput: \\n{x}\")\n",
    "\n",
    "    # model definition\n",
    "    model = MyAutoEncLSTM(input_size=num_features,\n",
    "                          hidden_size=hidden_size,\n",
    "                          embedding_dim=embedding_dim,\n",
    "                          num_layers=num_layers,\n",
    "                          device=device)\n",
    "\n",
    "    # model output\n",
    "    output = model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
